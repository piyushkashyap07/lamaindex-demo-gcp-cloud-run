# Propensity Score Analysis - Full Stack Application

A complete web application for analyzing company propensity scores using AI-powered multi-agent workflows. This application combines a FastAPI backend with a modern HTML/CSS/JavaScript frontend, all containerized for easy deployment.

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- API Keys (see Environment Variables section)

### 1. Clone and Setup
```bash
git clone <repository-url>
cd google-cloud-run-demo
```

### 2. Environment Configuration
```bash
# Copy the example environment file
cp env.example .env

# Edit .env with your actual API keys
nano .env
```

### 3. Deploy with Docker
```bash
# Build and run the application
docker-compose up --build

# Or run in detached mode
docker-compose up -d --build
```

### 4. Access the Application
- **Frontend**: http://localhost
- **API Documentation**: http://localhost/docs
- **Health Check**: http://localhost/server-check

## ğŸ—ï¸ Architecture

### Frontend (HTML/CSS/JavaScript)
- **Location**: `Frontend/`
- **Features**:
  - Modern responsive design
  - Real-time API interactions
  - Toast notifications
  - Loading states and progress indicators
  - Conversation history management

### Backend (FastAPI)
- **Location**: `Backend/`
- **Features**:
  - Multi-agent AI workflow
  - MongoDB integration
  - Vector search capabilities
  - Comprehensive API endpoints

### Unified Deployment
- **Nginx**: Serves frontend and proxies API requests
- **Supervisor**: Manages both Nginx and FastAPI processes
- **Single Container**: Complete application in one Docker image

## ğŸ“ Project Structure

```
google-cloud-run-demo/
â”œâ”€â”€ Frontend/                    # Frontend application
â”‚   â”œâ”€â”€ index.html              # Main HTML file
â”‚   â”œâ”€â”€ styles.css              # CSS styling
â”‚   â””â”€â”€ script.js               # JavaScript functionality
â”œâ”€â”€ Backend/                     # Backend application
â”‚   â”œâ”€â”€ app/                     # FastAPI application
â”‚   â”‚   â”œâ”€â”€ controllers/         # API controllers
â”‚   â”‚   â”œâ”€â”€ helpers/             # Utility modules
â”‚   â”‚   â”œâ”€â”€ models/              # Data models
â”‚   â”‚   â”œâ”€â”€ prompts/             # AI agent prompts
â”‚   â”‚   â”œâ”€â”€ routes/              # API routes
â”‚   â”‚   â””â”€â”€ workflows/           # Multi-agent workflows
â”‚   â”œâ”€â”€ main.py                  # Application entry point
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â””â”€â”€ Dockerfile               # Backend Docker config
â”œâ”€â”€ Dockerfile                   # Unified deployment Dockerfile
â”œâ”€â”€ docker-compose.yml           # Docker Compose configuration
â”œâ”€â”€ env.example                  # Environment variables template
â””â”€â”€ README.md                    # This file
```

## ğŸ”§ Environment Variables

### Required API Keys
```bash
# Google API Key for Gemini LLM
GOOGLE_API_KEY=your_google_api_key_here

# Tavily API Key for web search
TAVILY_API_KEY=your_tavily_api_key_here

# OpenAI API Key for GPT-4o-mini and embeddings
OPENAI_API_KEY=your_openai_api_key_here

# Pinecone API Key for vector database
PINECONE_API_KEY=your_pinecone_api_key_here
```

### Database Configuration
```bash
# MongoDB connection string
MONGODB_URI=mongodb://localhost:27017

# MongoDB Atlas for vector search (optional)
MONGODB_RAG_URI=your_mongodb_atlas_uri_here
MONGODB_RAG_DB=your_mongodb_rag_database_name
```

### Optional Services
```bash
# Argilla for feedback collection
ARGILLA_API_URL=http://localhost:4535
ARGILLA_API_KEY=your_argilla_api_key_here
```

## ğŸŒ API Endpoints

### Core Endpoints
- `GET /server-check` - Health check
- `POST /` - Create new conversation
- `POST /message-sync` - Analyze company (synchronous)
- `GET /get_conversations` - Retrieve conversation history

### Frontend Integration
The frontend automatically handles:
- Conversation creation
- Company analysis requests
- Results display with visual indicators
- Error handling and user feedback
- Conversation history management

## ğŸ¯ Usage Examples

### 1. Analyze a Company
1. Open http://localhost in your browser
2. Enter your email address
3. Enter a company name (e.g., "Meta", "Apple", "Tesla")
4. Click "Analyze Company"
5. View the propensity score and detailed analysis

### 2. View Analysis History
- The application automatically saves all analyses
- Click the refresh button to see conversation history
- Each analysis includes company name, score, and summary

### 3. API Integration
```bash
# Create conversation
curl -X POST "http://localhost/" \
     -H "Content-Type: application/json" \
     -d '{"email": "user@example.com"}'

# Analyze company
curl -X POST "http://localhost/message-sync" \
     -H "Content-Type: application/json" \
     -d '{"conversation_id": "conversation_id", "user_message": "Analyze Meta"}'
```

## ğŸ³ Docker Deployment Options

### Option 1: Docker Compose (Recommended)
```bash
# Full stack with all services
docker-compose up --build

# With local MongoDB
docker-compose --profile local-db up --build

# With Argilla feedback collection
docker-compose --profile argilla up --build
```

### Option 2: Docker Build
```bash
# Build the unified image
docker build -t propensity-analysis-app .

# Run the container
docker run -p 80:80 \
  -e GOOGLE_API_KEY=your_key \
  -e TAVILY_API_KEY=your_key \
  -e OPENAI_API_KEY=your_key \
  -e PINECONE_API_KEY=your_key \
  propensity-analysis-app
```

### Option 3: Google Cloud Run
```bash
# Build and push to Google Container Registry
docker build -t gcr.io/PROJECT_ID/propensity-analysis-app .
docker push gcr.io/PROJECT_ID/propensity-analysis-app

# Deploy to Cloud Run
gcloud run deploy propensity-analysis-app \
  --image gcr.io/PROJECT_ID/propensity-analysis-app \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --port 80
```

## ğŸ” Features

### Frontend Features
- **Responsive Design**: Works on desktop, tablet, and mobile
- **Real-time Updates**: Live progress indicators during analysis
- **Visual Indicators**: Color-coded propensity scores (ğŸŸ¢ High, ğŸŸ¡ Medium, ğŸ”´ Low)
- **Error Handling**: User-friendly error messages and retry options
- **Conversation Management**: Persistent analysis history
- **Toast Notifications**: Success, error, and info messages

### Backend Features
- **Multi-Agent Analysis**: 4 specialized AI agents analyze different aspects
- **Propensity Scoring**: 1-10 scale with detailed rationale
- **Vector Search**: MongoDB Atlas integration for document retrieval
- **Web Research**: Tavily API integration for real-time data
- **Conversation Persistence**: MongoDB storage for all interactions
- **Comprehensive Logging**: Structured logging for debugging and monitoring

### AI Analysis Agents
1. **Marketing Signal Agent**: Analyzes advertising strategy and budget
2. **Leadership Change Agent**: Detects executive changes and strategic impacts
3. **Competitor Ad Spend Agent**: Evaluates competitive advertising landscape
4. **Three Month Report Agent**: Assesses financial health and stock performance

## ğŸ› ï¸ Development

### Local Development
```bash
# Backend only
cd Backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python main.py

# Frontend only (serve with any HTTP server)
cd Frontend
python -m http.server 8000
# Access at http://localhost:8000
```

### Testing
```bash
# Test API endpoints
curl http://localhost/server-check

# Test frontend
open http://localhost
```

## ğŸ“Š Monitoring and Logs

### Application Logs
- **Location**: `./logs/` directory
- **Backend Logs**: `/var/log/supervisor/fastapi_*.log`
- **Nginx Logs**: `/var/log/nginx/*.log`

### Health Monitoring
- **Health Check**: `GET /server-check`
- **Status**: Returns server status and timestamp
- **Monitoring**: Built-in health check endpoint

## ğŸ”’ Security Considerations

### Environment Variables
- Never commit API keys to version control
- Use `.env` files for local development
- Use secure secret management in production

### API Security
- CORS configured for cross-origin requests
- Input validation using Pydantic models
- Error handling prevents information leakage

### Production Deployment
- Use HTTPS in production
- Configure proper firewall rules
- Monitor API usage and rate limiting

## ğŸš€ Production Deployment

### Google Cloud Run
1. Build and push Docker image to GCR
2. Deploy with proper environment variables
3. Configure custom domain (optional)
4. Set up monitoring and alerting

### Other Platforms
- **AWS ECS/Fargate**: Use the Dockerfile directly
- **Azure Container Instances**: Deploy with environment variables
- **Kubernetes**: Use the Docker image with proper configuration

## ğŸ“ˆ Scaling Considerations

### Horizontal Scaling
- Stateless backend design supports multiple instances
- MongoDB can be scaled independently
- Nginx load balancer can distribute traffic

### Performance Optimization
- Vector search caching
- API response caching
- CDN for static frontend assets

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For support and questions:
- Check the API documentation at `/docs`
- Review the logs in the `logs/` directory
- Test the health check endpoint
- Verify environment variables are set correctly

---

**Built with â¤ï¸ for TelevisaUnivision Business Intelligence**
